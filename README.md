# Hybrid-News-Headline-Generation

---

## ğŸ“Œ Project Overview

This project performs **automatic text summarization** on a large news dataset.  
It combines traditional word embeddings (**fastText**) with state-of-the-art transformer-based summarization (**Flan-T5**) to generate concise summaries from long news articles.

The project demonstrates a complete NLP pipeline including preprocessing, embedding generation, model loading, and summarization output.

---

## ğŸ¯ Objective

To build an efficient text-summarization system that:

- Understands long news articles  
- Generates high-quality, human-like summaries  
- Combines embedding techniques (fastText) with transformer models (Flan-T5)  
- Demonstrates real-world NLP workflow  

---

## ğŸ§  Key Features

- fastText word embeddings for text representation  
- Flan-T5 transformer model for abstractive summarization  
- Preprocessing: cleaning, tokenizing, normalization  
- Works on real news dataset with headlines + article text  
- Produces short, meaningful summaries  
- Jupyter Notebook implementation for easy execution  

---

## ğŸ›  Tech Stack

- **Python**
- **pandas, NumPy**
- **fastText**
- **Transformers (Hugging Face)**
- **Flan-T5**
- **NLTK / regex**
- **Jupyter Notebook**

---

## ğŸ“‚ Dataset

The dataset used: **`news_summary_more.csv`**  
**It contains**:

- `headlines`: Short article headline  
- `text`: Full news article text  

**Sample**:

`Headline`: Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.

`Text`: Delhi techie wins free food from Swiggy for one year on CRED

---

## âš™ï¸ NLP Pipeline

### 1ï¸âƒ£ Data Preprocessing
- Lowercasing  
- Punctuation removal  
- Stopword removal  
- Cleaning HTML / URLs  
- Tokenization  

### 2ï¸âƒ£ fastText Embedding
- Loaded pre-trained **fastText crawl vectors** (2M word vectors)  
- Generated numerical vector representations for each text  
- Used embeddings for semantic understanding  

### 3ï¸âƒ£ Abstractive Summarization (Flan-T5)
- Loaded model: `google/flan-t5-base`  
- Tokenized article text  
- Generated summaries using T5â€™s encoder-decoder transformer  
- Post-processed outputs for readability  

### 4ï¸âƒ£ Evaluation & Output
- Summaries generated for both headlines + article body  
- Compared original text vs generated summaries  
- Exported sample outputs for validation  

---

## ğŸ“ Project Structure

text-summarization/
â”‚â”€â”€ Text_Summarization_using_fastText_and_Flan_t5.ipynb

â”‚â”€â”€ news_summary_more.csv

â”‚â”€â”€ README.md

â”‚â”€â”€ requirements.txt

---

## â–¶ï¸ How to Run Locally

### 1. Install dependencies

pip install -r requirements.txt

### 2. Open the notebook

jupyter notebook "Text_Summarization_using_fastText_and_Flan_t5.ipynb"

### 3. Run all cells

This will:
âœ” Load fastText embeddings
âœ” Load Flan-T5 model
âœ” Generate summaries

---

ğŸš€ **Future Enhancements**

Deploy summarizer using Streamlit

Add ROUGE/BLEU evaluation metrics

Use larger models (Flan-T5-large / T5-3B)

Add extractive + abstractive hybrid summarization

Build API endpoint for real-time summarization

---

ğŸ‘¤ **Author**

**Srikanth Edigi**

ğŸ“§ **Email**: srikanthgoud9515@gmail.com

ğŸ”— **LinkedIn**: http://www.linkedin.com/in/srikanth-edigi-4739b125b 
